{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"LabelledData.txt\",sep=\",,,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1483, 2)\n"
     ]
    }
   ],
   "source": [
    "data=shuffle(data, random_state=0)\n",
    "print data.shape\n",
    "X=data['sentence']\n",
    "label=data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer(max_features=100)\n",
    "countVectorTrain=countvect.fit_transform(X_train)\n",
    "countVectorTest=countvect.transform(X_test)\n",
    "countfeatureTrain=pd.DataFrame(countVectorTrain.toarray(), columns=countvect.get_feature_names()) \n",
    "countfeatureTest=pd.DataFrame(countVectorTest.toarray(), columns=countvect.get_feature_names()) \n",
    "\n",
    "tfidfvect = TfidfVectorizer(max_features=100)\n",
    "tfidfVectorTrain = tfidfvect.fit_transform(X_train)\n",
    "tfidfVectorTest = tfidfvect.transform(X_test)\n",
    "tfidfeatureTrain=pd.DataFrame(tfidfVectorTrain.toarray(), columns=tfidfvect.get_feature_names()) \n",
    "tfidfeatureTest=pd.DataFrame(tfidfVectorTest.toarray(), columns=tfidfvect.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1186, 100)\n",
      "(1186, 100)\n",
      "(297, 100)\n",
      "(297, 100)\n"
     ]
    }
   ],
   "source": [
    "print tfidfeatureTrain.shape\n",
    "print countfeatureTrain.shape\n",
    "\n",
    "print tfidfeatureTest.shape\n",
    "print countfeatureTest.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureCount=countvect.get_feature_names()\n",
    "featureTfidf=tfidfvect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTrainAndAccuracy(model,trainingfeature,testingfeature):\n",
    "    clf=None\n",
    "    if(model==\"logistic\"):\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(trainingfeature, y_train)\n",
    "        \n",
    "    elif (model==\"decisiontree\"):\n",
    "        clf = DecisionTreeClassifier().fit(trainingfeature, y_train)\n",
    "        \n",
    "    elif(model==\"knn\"):\n",
    "        clf = KNeighborsClassifier()\n",
    "        clf.fit(trainingfeature, y_train)\n",
    "        \n",
    "    elif(model==\"naive\"):\n",
    "        clf = MultinomialNB().fit(trainingfeature, y_train)\n",
    "    \n",
    "    if(clf!=None):\n",
    "        print 'Accuracy of ',model,' classifier on training set: {:.2f}'.format(clf.score(trainingfeature, y_train))\n",
    "        print 'Accuracy of ',model,' classifier on test set: {:.2f}'.format(clf.score(testingfeature, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Result using count vector as features---------------\n",
      "Accuracy of  logistic  classifier on training set: 0.97\n",
      "Accuracy of  logistic  classifier on test set: 0.96\n",
      "Accuracy of  decisiontree  classifier on training set: 1.00\n",
      "Accuracy of  decisiontree  classifier on test set: 0.95\n",
      "Accuracy of  knn  classifier on training set: 0.94\n",
      "Accuracy of  knn  classifier on test set: 0.92\n",
      "Accuracy of  naive  classifier on training set: 0.94\n",
      "Accuracy of  naive  classifier on test set: 0.92\n",
      "----------------Result using TFIDF as features-------------------------\n",
      "Accuracy of  logistic  classifier on training set: 0.96\n",
      "Accuracy of  logistic  classifier on test set: 0.94\n",
      "Accuracy of  decisiontree  classifier on training set: 1.00\n",
      "Accuracy of  decisiontree  classifier on test set: 0.93\n",
      "Accuracy of  knn  classifier on training set: 0.89\n",
      "Accuracy of  knn  classifier on test set: 0.87\n",
      "Accuracy of  naive  classifier on training set: 0.91\n",
      "Accuracy of  naive  classifier on test set: 0.90\n"
     ]
    }
   ],
   "source": [
    "modelList=[\"logistic\",\"decisiontree\",\"knn\",\"naive\"]\n",
    "print \"---------------------Result using count vector as features---------------\"\n",
    "for model in modelList:\n",
    "    modelTrainAndAccuracy(model,countfeatureTrain,countfeatureTest)\n",
    "print \"----------------Result using TFIDF as features-------------------------\"\n",
    "for model in modelList:\n",
    "    modelTrainAndAccuracy(model,tfidfeatureTrain,tfidfeatureTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best algorithm seems to be using logisitc regression using count vector as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
